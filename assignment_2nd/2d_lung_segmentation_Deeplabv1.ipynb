{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjmNtVQ8EuTP"
      },
      "source": [
        "# 2D Lung Segmentation for Deeblabv1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h16wwNZwEuTU"
      },
      "source": [
        "According to the World Heath Organization, lung cancer is the leading cause of cancer-related deaths worldwide, accounting for an estimated 1.4 million deaths in 2018 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3864624/). CT scans are now being used in the United States to screen high-risk individuals for lung cancer. In order to detect cancerous lesions in scans, a useful first step is to segment the lungs in the image. (Then a researcher would use just the segmented image as input to another model). In this notebook we will perform segmentation on lungs in CT scans using a U-Net model (https://sites.pitt.edu/~sjh95/related_papers/u-net.pdf).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_6VGu2WEuTV"
      },
      "outputs": [],
      "source": [
        "%env TF_CPP_MIN_LOG_LEVEL=3  # silence some TensorFlow warnings and logs.\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "# Please feel free to play with hyperparameters, but submit the assignment with the original values.\n",
        "IMAGE_SIZE = (128, 128)\n",
        "TRAIN_VAL_TEST_SPLIT = (0.6, 0.2, 0.2)\n",
        "BATCH_SIZE = 16\n",
        "SEED = 220\n",
        "EPOCHS = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yeOwU0NEuTX"
      },
      "source": [
        "## Section 1: Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIAR_TycEuTX"
      },
      "source": [
        "We will be using a Kaggle dataset from https://www.kaggle.com/kmader/finding-lungs-in-ct-data. Similar to part 1, create an API token to set in your environment and download the dataset from Kaggle through the following commands.\n",
        "\n",
        "```kaggle datasets download -d kmader/finding-lungs-in-ct-data```\n",
        "\n",
        "```unzip finding-lungs-in-ct-data.zip```\n",
        "\n",
        "This should take a couple of minutes. Fill IMAGE_DIR and MASK_DIR with the output paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhaNp93vEuTY"
      },
      "outputs": [],
      "source": [
        "# FILL IN CODE HERE #\n",
        "\n",
        "IMAGE_DIR = '' # replace with your path\n",
        "MASK_DIR = '' # replace with your path\n",
        "PROJECT_DIR = ''\n",
        "\n",
        "# FILL IN CODE HERE #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_FC5q4lEuTZ"
      },
      "source": [
        "**Q1b.1**: First let's load the dataset from the saved folders. Our dataset contains 267 CT scans and the corresponding segmentations. Implement the ```load_data``` function below.\n",
        "\n",
        "For each file (CT scan or mask):\n",
        "\n",
        "1) Read the image using ```cv2.imread```. Make sure to read all channels with the ```cv2.IMREAD_UNCHANGED``` argument.\n",
        "\n",
        "2) Normalize the image by its maximum and minmum value, so each image will be in the range [0,1].\n",
        "\n",
        "3) For the segmentation mask only, normalize the mask by its maximum value and convert the numpy array to type `int16`.\n",
        "\n",
        "4) Resize the image to ```IMAGE_SIZE``` using the ```cv2.resize``` function. For images, use the ```cv2.INTER_LANCZOS4``` interpolator, and for segmentation masks use the `INTER_NEAREST` interpolator.\n",
        "\n",
        "\n",
        "Then split all the data into three training (60% of data), validation (20% of data), and test (20% of data). The expected shapes of the ```train_images``` and ```train_masks``` arrays are (160, 128, 128, 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iowuUKmCEuTa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def load_data(IMAGE_DIR, MASK_DIR):\n",
        "    \"\"\" Load images and mask from the saved folders, IMG_DIR and MASK_dir and split them to\n",
        "        train, validation, and test sets.\n",
        "\n",
        "        Input:\n",
        "            IMAGE_DIR (str): path to the folder containing ct scan images\n",
        "            MASK_DIR (str): path to the folder containing corresponding masks\n",
        "        Output:\n",
        "            train_images, val_images, test_images (numpy array of shape (number of images, IMAGE_SIZE)):\n",
        "                preprocessed images split in 0.6, 0.2, 0.2 respectively\n",
        "            train_masks, val_masks, test_masks (numpy array of shape (number of masks, IMAGE_SIZE)):\n",
        "                preprocessed masks split in 0.6, 0.2, 0.2 respectively\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    masks = []\n",
        "    for i, file in enumerate(sorted(os.listdir(IMAGE_DIR))):\n",
        "        image_path = os.path.join(IMAGE_DIR, file)\n",
        "        mask_path = os.path.join(MASK_DIR, file)\n",
        "\n",
        "        # FILL IN CODE HERE #\n",
        "\n",
        "        # FILL IN CODE HERE #\n",
        "\n",
        "    all_images = np.stack(images)[:,:,:,np.newaxis]\n",
        "    all_masks = np.stack(masks)[:,:,:,np.newaxis]\n",
        "\n",
        "    # FILL IN CODE HERE #\n",
        "\n",
        "    # FILL IN CODE HERE #\n",
        "\n",
        "    return train_images, train_masks, val_images, val_masks, test_images, test_masks\n",
        "\n",
        "train_images, train_masks, val_images, val_masks, test_images, test_masks = load_data(IMAGE_DIR, MASK_DIR)\n",
        "print('Train images: ', train_images.shape)\n",
        "print('Train masks: ', train_masks.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOoebs54EuTb"
      },
      "source": [
        "**Q1b.2**: We will now implement data augmentation. As we can see from the previous part, we only have 160 training examples. Neural networks usually need large number of training examples to succeed in learning a task such as segmentation. Therefore, we will use data augmentation techniques to simulate exposing our model to many more training examples. We will use the following augmentations on our data:\n",
        "\n",
        "1) Random horizontal shift with at most 0.1 of image width\n",
        "\n",
        "2) Random vertical shift with at most 0.1 of image height\n",
        "\n",
        "3) Random rotation with at most 10 degrees\n",
        "\n",
        "4) Random zoom with at most 0.1 times zoom-in or zoom-out\n",
        "\n",
        "Explain why these augmentations should help improve the accuracy of the model. Is it possible for data augmentation to instead decrease the performance of the trained model on the test set? If so, explain under what situation this could happen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0qBqf0GEuTc"
      },
      "source": [
        "*Written answer*:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGbpBSv8EuTc"
      },
      "source": [
        "**Q1b.3**: For data augmentation in Keras, we will use the ```ImageDataGenerator``` class which has several built-in data augmentation methods. Look at the documentation of [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) and implement the following function. You only need to define `image_datagen` and `mask_datagen`.\n",
        "\n",
        "The final print statement will check that your data generator is returning data with the right shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0NEF0SWEuTc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def create_generator(train_images, train_masks):\n",
        "    \"\"\" Creat a generator based on training images and masks.\n",
        "\n",
        "        Input:\n",
        "            train_images (np): array of training images\n",
        "            train_masks (np): array of training masks\n",
        "        Output:\n",
        "            data_generator (generator function): generator which yields images and masks after data augmenetation\n",
        "    \"\"\"\n",
        "    # FILL IN CODE HERE #\n",
        "    # Define `image_datagen` and `mask_datagen`\n",
        "    # FILL IN CODE HERE #\n",
        "\n",
        "    image_datagen.fit(train_images, augment=True, seed=SEED)\n",
        "    mask_datagen.fit(train_masks, augment=True, seed=SEED)\n",
        "\n",
        "    image_generator = image_datagen.flow(train_images, batch_size=BATCH_SIZE, seed=SEED)\n",
        "    mask_generator = mask_datagen.flow(train_masks, batch_size=BATCH_SIZE, seed=SEED)\n",
        "    data_generator = zip(image_generator, mask_generator)\n",
        "\n",
        "\n",
        "    return data_generator\n",
        "\n",
        "data_generator = create_generator(train_images, train_masks)\n",
        "img, mask = next(data_generator)\n",
        "print(f\"Image batch shape {img.shape}, mask batch shape {mask.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZgL5oymEuTd"
      },
      "source": [
        "Run the following code to convert the generator (for the training set) and numpy arrays (for the validation and test sets) to TensorFlow datasets. Don't worry about the details; in part 3 of this assignment you will get practice writing generators for TensorFlow datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu_xPmMlEuTd"
      },
      "outputs": [],
      "source": [
        "def train_generator():\n",
        "    while True:\n",
        "        image_batch, mask_batch = next(data_generator)\n",
        "        yield image_batch, mask_batch\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(train_generator,\n",
        "                     output_types=(tf.float32, tf.float32),\n",
        "                     output_shapes=([None, IMAGE_SIZE[0], IMAGE_SIZE[1], 1],\n",
        "                                    [None, IMAGE_SIZE[0], IMAGE_SIZE[1], 1])\n",
        "                                              ).repeat()\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_masks)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_masks)).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3M3SB0dEuTd"
      },
      "source": [
        "**Q1b.4**: Let's take a look at some image examples and their corresponding masks from the training dataset. Take a batch from the ```train_dataset``` and plot four images and their corresponding masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dao1hyVoEuTd"
      },
      "outputs": [],
      "source": [
        "# FILL IN CODE HERE #\n",
        "\n",
        "# FILL IN CODE HERE #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwpJXKkVEuTd"
      },
      "source": [
        "## Section 2: Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLHejPRYEuTd"
      },
      "source": [
        "Let's implement the Deeplab v1 model for our segmentation task. You can see the model architecture described in the Deeplab paper here: (arxiv.org/abs/1412.7062) , Figure 1. We'll be implementing a simpler version of this without a weighted loss for class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DahJeZLIEuTe"
      },
      "source": [
        "**Q1b.5**: At a high level, explain how U-Net works and why it is more suitable for the segmentation task relative to a simple convolutional neural network (CNN).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvejJ5khEuTe"
      },
      "source": [
        "*Written answer*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckDVSR8kEuTe"
      },
      "source": [
        "**Q1b.6**: Implement a simplified version of Deeplab based on thesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Dropout, concatenate\n",
        "class Deeplabv1(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Deeplabv3, self).__init__()\n",
        "\n",
        "        # FILL IN CODE HERE #\n",
        "\n",
        "        # FILL IN CODE HERE #\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # FILL IN CODE HERE #\n",
        "\n",
        "        # FILL IN CODE HERE #\n",
        "\n",
        "        return output\n",
        "\n",
        "# create model\n",
        "model = Deeplabv1()\n",
        "\n",
        "# test that the output data shape is reasonable\n",
        "img_batch, mask_batch = next(iter(test_dataset))\n",
        "sample_out = model(img_batch)\n",
        "print(f\"Input shape {img_batch.shape}, model out shape {sample_out.shape}\")"
      ],
      "metadata": {
        "id": "lPlniyCwKwzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll_EeB_OEuTe"
      },
      "source": [
        "**Q1b.7**: Which loss function do you think is most appropriate for our task here? Why? After selecting the loss function, compile the model using the Adam optimizer with default learning rate. Add the accuracy metric.\n",
        "\n",
        "(Note that the UNet paper describes a special weighting coefficient that makes its loss function different to the one you may choose; you don't have to implement this weighting.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RFtkrbGEuTe"
      },
      "source": [
        "*Written answer*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfb3e7iuEuTe"
      },
      "outputs": [],
      "source": [
        "# FILL IN CODE HERE #\n",
        "model.compile(\n",
        "\n",
        ")\n",
        "# FILL IN CODE HERE #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe07xMEVEuTf"
      },
      "source": [
        "**Q1b.8**: Before training the model, let's first set a learning rate scheduler. This will adjust the learning rate during the training of the model. Why can it be useful to use a learning rate schedule to train complex neural networks?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FTyPpa6EuTf"
      },
      "source": [
        "*Written answer*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nINBUZDsEuTf"
      },
      "source": [
        "Now we are going to train our model for 40 epochs. Implement the following function such that the learning rate for the first 20 epochs is 0.001, and after that it decreases exponentially with a factor of 0.1. For more information, please look at the ```ExponentialDecay``` documentation in Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gciYR8ywEuTf"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch):\n",
        "    \"\"\" Schedule the learning rate to be 0.0001 for first\n",
        "        20 epoch, and decrease exponentially by a factor of 0.1\n",
        "        for all remaining epochs.\n",
        "\n",
        "        Input:\n",
        "            epoch (int)\n",
        "        Output:\n",
        "            learning_rate (float)\n",
        "    \"\"\"\n",
        "    # FILL IN CODE HERE #\n",
        "\n",
        "    # FILL IN CODE HERE #\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVoTo1dOEuTf"
      },
      "source": [
        "**Q1b.9**: Train the model using the ```model.fit``` function in the Keras API. We compute the value of `steps_per_epoch` which tells the API how many times to sample from the TensorFlow dataset object. It should be passed as an argument to `model.fit()`. To enable the learning rate schedule we just implemented, pass it as a callback to `model.fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heqcut2IEuTf"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = int(len(os.listdir(IMAGE_DIR)) * TRAIN_VAL_TEST_SPLIT[0]) // BATCH_SIZE # pass this arg to fit()\n",
        "\n",
        "\n",
        "hist = model.fit(\n",
        "    # FILL IN CODE HERE #\n",
        "\n",
        "    # FILL IN CODE HERE #\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-_8VgF2EuTg"
      },
      "source": [
        "Using the `hist` variable returned from running the `fit` command above, run the following code to plot the training and validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVl4FK9YEuTg"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(range(EPOCHS), hist.history['loss'], label='Training loss')\n",
        "plt.plot(range(EPOCHS), hist.history['val_loss'], label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-BfWRdqEuTg"
      },
      "source": [
        "## Section 3: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGa5EQzQEuTg"
      },
      "source": [
        "**Q1b.10**: Use ```model.evaluate``` to evaluate the accuracy of the model on the test set. You should have an accuracy greater than 0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMjMrTC3EuTg"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2ePt_TwEuTg"
      },
      "source": [
        "**Q1b.11**: Based on the loss and accuracy on the test set, do you think we are overfitting? Please describe three methods that can be used to avoid overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU1FIvMQEuTg"
      },
      "source": [
        "*Written answer*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ38oT9REuTg"
      },
      "source": [
        "**Q1b.12**: What is Intersection over Union (IoU) and why it is a useful metric for the segmentation task?\n",
        "Implement the following function using the definition of IoU. Note that the ```np.logical_and``` and ```np.logical_or``` could be useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txvgkl_fEuTl"
      },
      "source": [
        "*Written answer*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-pJCjThEuTl"
      },
      "outputs": [],
      "source": [
        "def compute_IoU(target, prediction):\n",
        "    \"\"\"\n",
        "    Evaluate the intersection over union score for a single prediction and ground truth value\n",
        "\n",
        "    Parameters:\n",
        "    target: (np.ndarray) : The ground truth label values\n",
        "    prediction (np.ndarray): The labels predicted by the model\n",
        "    \"\"\"\n",
        "    # FILL IN CODE HERE #\n",
        "\n",
        "    # FILL IN CODE HERE #\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myieZk3tEuTl"
      },
      "source": [
        "**Q1b.13**: Using the `compute_IoU` function, compute the mean IoU on the test set and print the result. Compute the IoU for each image separately, and then take the mean over images. You can binarize the prediction mask with a threshold of 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYFS7-zxEuTl"
      },
      "outputs": [],
      "source": [
        "# FILL IN CODE HERE #\n",
        "\n",
        "# FILL IN CODE HERE #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJl4fFFKEuTm"
      },
      "source": [
        "**Q1b.14**: Let's make some predictions! Plot four test images, their corresponding ground truth mask, and the model prediction. Make sure to show at least one image for each of the IoU ranges of [0.85, 0.9], [0.9, 0.95], and [0.95, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvPtZCkhEuTm"
      },
      "outputs": [],
      "source": [
        "# FILL IN CODE HERE #\n",
        "\n",
        "\n",
        "# FILL IN CODE HERE #"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}